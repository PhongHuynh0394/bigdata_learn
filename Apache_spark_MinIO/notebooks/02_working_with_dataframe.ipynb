{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSession\n",
    "A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files.\n",
    "The entry point to programming Spark with the Dataset and DataFrame API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"pyspark-dataframe-demo-{}\".format(datetime.today()))\n",
    "        .master(\"spark://spark-master:7077\")      \n",
    "        .getOrCreate())\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "# spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7281043f3345:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-dataframe-demo-2023-03-23 05:35:45.440571</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=pyspark-dataframe-demo-2023-03-23 05:35:45.440571>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "A distributed collection of data grouped into named columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From list of tuples, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1='Alice', _2=1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(\"Alice\", 1)]\n",
    "spark.createDataFrame(l).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l, [\"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(l, [\"name\", \"age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=1, name='Alice')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [{\"name\": \"Alice\", \"age\": 1}]\n",
    "spark.createDataFrame(d).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "|  1|Alice|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(d).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1='Alice', _2=1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(\"Alice\", 1)]\n",
    "rdd = sc.parallelize(l)\n",
    "spark.createDataFrame(rdd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Alice', age=1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with list of column names\n",
    "df = spark.createDataFrame(rdd, [\"name\", \"age\"])\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Alice', age=1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with Row definition\n",
    "from pyspark.sql import Row\n",
    "Person = Row(\"name\", \"age\")\n",
    "person = rdd.map(lambda r: Person(*r))\n",
    "df2 = spark.createDataFrame(person)\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Alice', age=1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with schema definition\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "  ])\n",
    "df3 = spark.createDataFrame(rdd, schema)\n",
    "df3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(a='Alice', b=1)]\n",
      "[Row(value=1)]\n"
     ]
    }
   ],
   "source": [
    "# with string definition, New in version 2.0.\n",
    "rdd = sc.parallelize(l)\n",
    "print(spark.createDataFrame(rdd, \"a: string, b: int\").collect())\n",
    "\n",
    "rdd = rdd.map(lambda row: row[1])\n",
    "print(spark.createDataFrame(rdd, \"int\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Alice', age=1)]\n",
      "[Row(0='Alice', 1=2)]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "print(spark.createDataFrame(df.toPandas()).collect())\n",
    "print(spark.createDataFrame(pandas.DataFrame([[\"Alice\", 2]])).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age\n",
       "0  Alice    1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|    N|  A|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New in version 2.0\n",
    "df.createOrReplaceTempView(\"table1\")\n",
    "df2 = spark.sql(\"SELECT name as N, age as A from table1\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table1', 'table2']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.registerDataFrameAsTable(df, \"table1\")\n",
    "sqlContext.registerDataFrameAsTable(df2, \"table2\")\n",
    "sqlContext.tableNames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM table1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |   table1|      false|\n",
      "|         |   table2|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.tables().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |   table1|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = sqlContext.tables()\n",
    "df3.filter(\"tableName = 'table1'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.dropTempTable(\"table1\")\n",
    "sqlContext.dropTempTable(\"table2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.tableNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF: User Defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:281: FutureWarning: Deprecated in 2.3.0. Use spark.udf.register instead.\n",
      "  warnings.warn(\"Deprecated in 2.3.0. Use spark.udf.register instead.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(stringLengthString(test)='4')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.registerFunction(\"stringLengthString\", lambda x: len(x))\n",
    "sqlContext.sql(\"SELECT stringLengthString('test')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:281: FutureWarning: Deprecated in 2.3.0. Use spark.udf.register instead.\n",
      "  warnings.warn(\"Deprecated in 2.3.0. Use spark.udf.register instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|stringLengthInt(test)|\n",
      "+---------------------+\n",
      "|                    4|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "sqlContext.registerFunction(\"stringLengthInt\", lambda x: len(x), IntegerType())\n",
    "sqlContext.sql(\"SELECT stringLengthInt('test')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stringLengthInt(test)=4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.udf.register(\"stringLengthInt\", lambda x: len(x), IntegerType())\n",
    "sqlContext.sql(\"SELECT stringLengthInt('test')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = [(\"Alice\", 2, 12), (\"Bob\", 5, 25)]\n",
    "rdd = sc.parallelize(l)\n",
    "df = sqlContext.createDataFrame(rdd, \"name: string, age: int, height: int\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = spark.createDataFrame(rdd, \"name: string, age: int, height: int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "df2 = spark.sql(\"select * from people\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(10).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n",
      "CPU times: user 5.46 ms, sys: 223 µs, total: 5.68 ms\n",
      "Wall time: 877 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = df.union(df).repartition(\"age\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "|  Bob|  5|    25|\n",
      "|Alice|  2|    12|\n",
      "+-----+---+------+\n",
      "\n",
      "CPU times: user 3.96 ms, sys: 0 ns, total: 3.96 ms\n",
      "Wall time: 616 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.repartition(7, \"age\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n",
      "CPU times: user 5.04 ms, sys: 155 µs, total: 5.2 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.repartition(\"name\", \"age\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+----+\n",
      "| name|age|height|age2|\n",
      "+-----+---+------+----+\n",
      "|Alice|  2|    12|   4|\n",
      "|  Bob|  5|    25|   7|\n",
      "+-----+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn(colName, col)\n",
    "# Returns a new DataFrame by adding a column or replacing the existing column that has the same name.\n",
    "df.withColumn(\"age2\", df.age + 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "| name|age2|height|\n",
      "+-----+----+------+\n",
      "|Alice|   2|    12|\n",
      "|  Bob|   5|    25|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"age\", \"age2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|ages|\n",
      "+----+\n",
      "|   2|\n",
      "|   5|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age.cast(\"string\").alias(\"ages\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|ages|\n",
      "+----+\n",
      "|   2|\n",
      "|   5|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age.cast(StringType()).alias(\"ages\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n",
    "Aggregate on the entire DataFrame without groups (shorthand for df.groupBy.agg())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(age)|\n",
      "+--------+\n",
      "|       5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"age\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(age)|\n",
      "+--------+\n",
      "|       2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.agg(F.min(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|count(1)|\n",
      "+-----+--------+\n",
      "|  Bob|       1|\n",
      "|Alice|       1|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf = df.groupBy(df.name)\n",
    "gdf.agg({\"*\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|count(1)|\n",
      "+-----+--------+\n",
      "|  Bob|       2|\n",
      "|Alice|       2|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"name\").agg({\"*\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|min(age)|\n",
      "+-----+--------+\n",
      "|Alice|       2|\n",
      "|  Bob|       5|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "gdf.agg(F.min(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[name#632], functions=[min(age#633)])\n",
      "   +- Exchange hashpartitioning(name#632, 200), ENSURE_REQUIREMENTS, [plan_id=2442]\n",
      "      +- HashAggregate(keys=[name#632], functions=[partial_min(age#633)])\n",
      "         +- Project [name#632, age#633]\n",
      "            +- Scan ExistingRDD[name#632,age#633,height#634]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf.agg(F.min(df.age)).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Bob</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   name  age\n",
       "0  Alice  Alice    2\n",
       "1    Bob    Bob    5"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df_as1 = df.alias(\"df_as1\")\n",
    "df_as2 = df.alias(\"df_as2\")\n",
    "joined_df = df_as1.join(df_as2, col(\"df_as1.name\") == col(\"df_as2.name\"), \"inner\")\n",
    "joined_df = joined_df.select(\"df_as1.name\", \"df_as2.name\", \"df_as2.age\")\n",
    "joined_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=true\n",
      "+- == Final Plan ==\n",
      "   *(5) SortMergeJoin [name#4], [name#299], Inner\n",
      "   :- *(3) Sort [name#4 ASC NULLS FIRST], false, 0\n",
      "   :  +- AQEShuffleRead coalesced\n",
      "   :     +- ShuffleQueryStage 0\n",
      "   :        +- Exchange hashpartitioning(name#4, 200), ENSURE_REQUIREMENTS, [plan_id=609]\n",
      "   :           +- *(1) Project [name#4]\n",
      "   :              +- *(1) Filter isnotnull(name#4)\n",
      "   :                 +- *(1) Scan ExistingRDD[name#4,age#5L]\n",
      "   +- *(4) Sort [name#299 ASC NULLS FIRST], false, 0\n",
      "      +- AQEShuffleRead coalesced\n",
      "         +- ShuffleQueryStage 1\n",
      "            +- Exchange hashpartitioning(name#299, 200), ENSURE_REQUIREMENTS, [plan_id=621]\n",
      "               +- *(2) Filter isnotnull(name#299)\n",
      "                  +- *(2) Scan ExistingRDD[name#299,age#300L]\n",
      "+- == Initial Plan ==\n",
      "   SortMergeJoin [name#4], [name#299], Inner\n",
      "   :- Sort [name#4 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(name#4, 200), ENSURE_REQUIREMENTS, [plan_id=596]\n",
      "   :     +- Project [name#4]\n",
      "   :        +- Filter isnotnull(name#4)\n",
      "   :           +- Scan ExistingRDD[name#4,age#5L]\n",
      "   +- Sort [name#299 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(name#299, 200), ENSURE_REQUIREMENTS, [plan_id=597]\n",
      "         +- Filter isnotnull(name#299)\n",
      "            +- Scan ExistingRDD[name#299,age#300L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('height', IntegerType(), True)])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(age)|\n",
      "+--------+\n",
      "|       7|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().sum(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|sum(age)|sum(height)|\n",
      "+--------+-----------+\n",
      "|       7|         37|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().sum(\"age\", \"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|     3.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().avg(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|avg(age)|avg(height)|\n",
      "+--------+-----------+\n",
      "|     3.5|       18.5|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().avg(\"age\", \"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'height']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = df\n",
    "t.age = df.age + 1\n",
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|count|\n",
      "+-----+----+-----+\n",
      "| null|null|    2|\n",
      "| null|   2|    1|\n",
      "| null|   5|    1|\n",
      "|Alice|null|    1|\n",
      "|Alice|   2|    1|\n",
      "|  Bob|null|    1|\n",
      "|  Bob|   5|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cube(*col): Create a multi-dimensional cube for the current DataFrame using the specified columns, so we can run aggregation on them.\n",
    "df.cube(\"name\", df.age).count().orderBy(\"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|                 2|\n",
      "|   mean|               3.5|\n",
      "| stddev|2.1213203435596424|\n",
      "|    min|                 2|\n",
      "|    max|                 5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe([\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+-----------------+\n",
      "|summary| name|               age|           height|\n",
      "+-------+-----+------------------+-----------------+\n",
      "|  count|    2|                 2|                2|\n",
      "|   mean| null|               3.5|             18.5|\n",
      "| stddev| null|2.1213203435596424|9.192388155425117|\n",
      "|    min|Alice|                 2|               12|\n",
      "|    max|  Bob|                 5|               25|\n",
      "+-------+-----+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('height', 'int')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan ExistingRDD[name#632,age#633,height#634]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "LogicalRDD [name#632, age#633, height#634], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, height: int\n",
      "LogicalRDD [name#632, age#633, height#634], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LogicalRDD [name#632, age#633, height#634], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Scan ExistingRDD[name#632,age#633,height#634]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|avg(age)|avg(height)|\n",
      "+--------+-----------+\n",
      "|     3.5|       18.5|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|avg(age)|\n",
      "+-----+--------+\n",
      "|Alice|     2.0|\n",
      "|  Bob|     5.0|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"name\").agg({\"age\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+\n",
      "| name|avg(age)|avg(height)|\n",
      "+-----+--------+-----------+\n",
      "|  Bob|     5.0|       25.0|\n",
      "|Alice|     2.0|       12.0|\n",
      "+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.name).avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|count|\n",
      "+-----+---+-----+\n",
      "|Alice|  2|    1|\n",
      "|  Bob|  5|    1|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"name\", df.age]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(age)|\n",
      "+--------+\n",
      "|       5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().max(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|max(age)|max(height)|\n",
      "+--------+-----------+\n",
      "|       5|         25|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().max(\"age\", \"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|     3.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().mean(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|avg(age)|avg(height)|\n",
      "+--------+-----------+\n",
      "|     3.5|       18.5|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy().mean(\"age\", \"height\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "|  2|Alice|\n",
      "|  5|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\", \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|Alice|    12|\n",
      "|  Bob|    25|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name\", \"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|Alice|    12|\n",
      "|  Bob|    25|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+---+------+\n",
      "|age|height| name|age|height|\n",
      "+---+------+-----+---+------+\n",
      "|  2|    12|Alice|  2|    12|\n",
      "|  5|    25|  Bob|  5|    25|\n",
      "+---+------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, df.name == df2.name, \"inner\").drop(df.name).drop(df.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Alice|\n",
      "|  Bob|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, \"name\", \"inner\").drop(\"age\", \"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  5|    80|\n",
      "|Alice| 10|    80|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "df = sc.parallelize([\n",
    "    Row(name=\"Alice\", age=5, height=80),\n",
    "    Row(name=\"Alice\", age=5, height=80),\n",
    "    Row(name=\"Alice\", age=10, height=80)\n",
    "  ]).toDF()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  5|    80|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates([\"name\", \"height\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|Alice|    12|\n",
      "|Alice|    12|\n",
      "|Alice|    12|\n",
      "| null|    25|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, df.name == df2.name, 'outer').select(df.name, df2.height).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|Alice|    80|\n",
      "|Alice|    80|\n",
      "|Alice|    80|\n",
      "|  Bob|  null|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, 'name', 'outer').select('name', df.height).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| name| age|\n",
      "+-----+----+\n",
      "| null|   2|\n",
      "|Alice|null|\n",
      "|Alice|null|\n",
      "|Alice|null|\n",
      "| null|   5|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond = [df.name == df2.name, df.age == df2.age]\n",
    "df.join(df2, cond, 'outer').select(df.name, df2.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|Alice|    12|\n",
      "|Alice|    12|\n",
      "|Alice|    12|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, 'name').select(df.name, df2.height).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, ['name', 'age']).select(df.name, df.age).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "|  Bob|  5|    25|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = [(\"Alice\", 2, 12), (\"Bob\", 5, 25)]\n",
    "rdd = sc.parallelize(l)\n",
    "df = sqlContext.createDataFrame(rdd, \"name: string, age: int, height: int\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "| Bob|  5|    25|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age > 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "| Bob|  5|    25|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age > 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|height|\n",
      "+-----+---+------+\n",
      "|Alice|  2|    12|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"age=2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Alice', age=2, height=12)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Alice', age=2, height=12)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Alice', age=2, height=12)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Bob', age=5, height=25), Row(name='Alice', age=2, height=12)]\n",
      "[Row(name='Bob', age=5, height=25), Row(name='Alice', age=2, height=12)]\n",
      "[Row(name='Bob', age=5, height=25), Row(name='Alice', age=2, height=12)]\n",
      "[Row(name='Alice', age=2, height=12), Row(name='Bob', age=5, height=25)]\n",
      "[Row(name='Bob', age=5, height=25), Row(name='Alice', age=2, height=12)]\n",
      "[Row(name='Bob', age=5, height=25), Row(name='Alice', age=2, height=12)]\n"
     ]
    }
   ],
   "source": [
    "# orderBy\n",
    "print(df.sort(df.age.desc()).collect())\n",
    "print(df.sort(\"age\", ascending=False).collect())\n",
    "print(df.orderBy(df.age.desc()).collect())\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "print(df.sort(asc(\"age\")).collect())\n",
    "print(df.sort(desc(\"age\"), \"name\").collect())\n",
    "print(df.orderBy([\"age\", \"name\"], ascending=[0, 1]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Alice', age=2, height=12)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(df.filter(df.name.endswith(\"ice\")).collect())\n",
    "print(df.filter(df.name.endswith(\"ice$\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     r|\n",
      "+------+\n",
      "|{1, b}|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get subfield RDD > RDD, gets a field by name in a StructField.\n",
    "from pyspark.sql import Row\n",
    "df1 = sc.parallelize([Row(r=Row(a=1, b=\"b\"))]).toDF()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|r.b|\n",
      "+---+\n",
      "|  b|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "|r.a|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.r.getField(\"b\")).show()\n",
    "df1.select(df1.r.getField(\"a\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|     l|             d|\n",
      "+------+--------------+\n",
      "|[1, 2]|{key -> value}|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RDD contains list and dictionary\n",
    "df1 = sc.parallelize([([1, 2], {\"key\": \"value\"})]).toDF([\"l\", \"d\"])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|l[0]|d[key]|\n",
      "+----+------+\n",
      "|   1| value|\n",
      "+----+------+\n",
      "\n",
      "+----+------+\n",
      "|l[0]|d[key]|\n",
      "+----+------+\n",
      "|   1| value|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.l.getItem(0), df1.d.getItem(\"key\")).show()\n",
    "df1.select(df1.l[0], df1.d[\"key\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|height|\n",
      "+-----+------+\n",
      "|  Tom|    80|\n",
      "|Alice|  null|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "df1 = sc.parallelize([Row(name=u\"Tom\", height=80), Row(name=u\"Alice\", height=None)]).toDF()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Tom', height=80)]\n",
      "[Row(name='Alice', height=None)]\n"
     ]
    }
   ],
   "source": [
    "print(df1.filter(df1.height.isNotNull()).collect())\n",
    "print(df1.filter(df1.height.isNull()).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Bob', age=5, height=25)]\n",
      "[Row(name='Alice', age=2, height=12)]\n"
     ]
    }
   ],
   "source": [
    "print(df[df.name.isin(\"Bob\", \"Mike\")].collect())\n",
    "print(df[df.age.isin(1, 2, 3)].collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Alice', age=2, height=12)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.name.like(\"Al%\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+\n",
      "| name|CASE WHEN (age > 3) THEN 1 ELSE 0 END|\n",
      "+-----+-------------------------------------+\n",
      "|Alice|                                    0|\n",
      "|  Bob|                                    1|\n",
      "+-----+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "name": "PySparkSQL",
  "notebookId": 2217893066036922
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
